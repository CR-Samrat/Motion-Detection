{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Subhadeep_Sarkar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow.keras.layers as k\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "dataset = []\n",
    "labels = []\n",
    "eligible_type = ['jpg','png']\n",
    "height = 70\n",
    "width = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2726 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2726/2726 [00:07<00:00, 378.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading closed eye images\n",
    "eye_close_folder = os.listdir('./Dataset/Closed_Eyes/')\n",
    "\n",
    "for img_id, each_image in enumerate(tqdm(eye_close_folder)):\n",
    "    if each_image.split('.')[1] in eligible_type:\n",
    "        image = cv.imread('./Dataset/Closed_Eyes/'+each_image)\n",
    "        image = Image.fromarray(image,'RGB')\n",
    "        image = image.resize((height,width))\n",
    "        image = np.array(image)\n",
    "\n",
    "        dataset.append(image)\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2726 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2726/2726 [00:06<00:00, 414.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading open eye images\n",
    "eye_open_folder = os.listdir('./Dataset/Open_Eyes/')\n",
    "\n",
    "for img_id, each_image in enumerate(tqdm(eye_open_folder)):\n",
    "    if each_image.split('.')[1] in eligible_type:\n",
    "        image = cv.imread('./Dataset/Open_Eyes/'+each_image)\n",
    "        image = Image.fromarray(image,'RGB')\n",
    "        image = image.resize((height,width))\n",
    "        image = np.array(image)\n",
    "\n",
    "        dataset.append(image)\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the dataset\n",
    "indices = [i for i in range(len(labels))]\n",
    "\n",
    "random.shuffle(indices)\n",
    "\n",
    "dataset = [dataset[i] for i in indices]\n",
    "labels = [labels[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = train_test_split(dataset, to_categorical(np.array(labels)), test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4361 4361\n",
      "545 545\n",
      "546 546\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(y_train))\n",
    "print(len(x_test),len(y_test))\n",
    "print(len(x_val),len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Subhadeep_Sarkar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Subhadeep_Sarkar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Input_shape = (height,width,3)\n",
    "\n",
    "inp = k.Input(shape=Input_shape)\n",
    "\n",
    "conv1 = k.Conv2D(32, kernel_size = (3,3), activation='relu', padding=\"same\")(inp)\n",
    "pool1 = k.MaxPool2D(pool_size=(2,2))(conv1)\n",
    "norm1 = k.BatchNormalization(axis = -1)(pool1)\n",
    "drop1 = k.Dropout(rate = 0.2)(norm1)\n",
    "\n",
    "conv2 = k.Conv2D(32, kernel_size = (3,3), activation='relu', padding=\"same\")(drop1)\n",
    "pool2 = k.MaxPool2D(pool_size=(2,2))(conv2)\n",
    "norm2 = k.BatchNormalization(axis = -1)(pool2)\n",
    "drop2 = k.Dropout(rate = 0.2)(norm2)\n",
    "\n",
    "conv3 = k.Conv2D(32, kernel_size = (3,3), activation='relu', padding=\"same\")(drop2)\n",
    "pool3 = k.MaxPool2D(pool_size=(2,2))(conv3)\n",
    "norm3 = k.BatchNormalization(axis = -1)(pool3)\n",
    "drop3 = k.Dropout(rate = 0.2)(norm3)\n",
    "\n",
    "flat = k.Flatten()(drop3)\n",
    "\n",
    "hidden1 = k.Dense(512, activation = 'relu')(flat)\n",
    "norm4 = k.BatchNormalization(axis = -1)(hidden1)\n",
    "drop4 = k.Dropout(rate = 0.2)(norm4)\n",
    "\n",
    "hidden2 = k.Dense(512, activation = 'relu')(drop4)\n",
    "norm5 = k.BatchNormalization(axis = -1)(hidden2)\n",
    "drop5 = k.Dropout(rate = 0.2)(norm5)\n",
    "\n",
    "out = k.Dense(2, activation=\"sigmoid\")(drop5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 70, 70, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 70, 70, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 35, 35, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 35, 35, 32)        128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 35, 35, 32)        0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 35, 35, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 17, 17, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 17, 17, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 17, 32)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 8, 8, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1336642 (5.10 MB)\n",
      "Trainable params: 1334402 (5.09 MB)\n",
      "Non-trainable params: 2240 (8.75 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs = inp, outputs = out)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Subhadeep_Sarkar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Subhadeep_Sarkar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "69/69 [==============================] - 13s 115ms/step - loss: 0.1999 - accuracy: 0.9321 - val_loss: 0.3019 - val_accuracy: 0.8846\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 7s 97ms/step - loss: 0.0832 - accuracy: 0.9725 - val_loss: 0.2961 - val_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 7s 97ms/step - loss: 0.0579 - accuracy: 0.9823 - val_loss: 0.0854 - val_accuracy: 0.9835\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 7s 98ms/step - loss: 0.0439 - accuracy: 0.9846 - val_loss: 0.0489 - val_accuracy: 0.9872\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 7s 97ms/step - loss: 0.0408 - accuracy: 0.9890 - val_loss: 0.0829 - val_accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 7s 97ms/step - loss: 0.0470 - accuracy: 0.9842 - val_loss: 0.0502 - val_accuracy: 0.9872\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 7s 97ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 0.0248 - val_accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 7s 101ms/step - loss: 0.0322 - accuracy: 0.9892 - val_loss: 0.0333 - val_accuracy: 0.9872\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 7s 94ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.0210 - val_accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 6s 92ms/step - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.0201 - val_accuracy: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1af6802f350>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(x_train), y_train, batch_size=64, verbose=1, epochs=10, validation_data=(np.array(x_val),y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0172 - accuracy: 0.9945\n",
      "Accuracy : 99.44953918457031\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy :\",model.evaluate(np.array(x_test), y_test)[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eye_state_classification_model.pkl','wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[120, 120, 120],\n",
       "         [118, 118, 118],\n",
       "         [118, 118, 118],\n",
       "         ...,\n",
       "         [109, 109, 109],\n",
       "         [108, 108, 108],\n",
       "         [107, 107, 107]],\n",
       "\n",
       "        [[119, 119, 119],\n",
       "         [117, 117, 117],\n",
       "         [118, 118, 118],\n",
       "         ...,\n",
       "         [108, 108, 108],\n",
       "         [108, 108, 108],\n",
       "         [107, 107, 107]],\n",
       "\n",
       "        [[119, 119, 119],\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         ...,\n",
       "         [107, 107, 107],\n",
       "         [107, 107, 107],\n",
       "         [107, 107, 107]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[110, 110, 110],\n",
       "         [111, 111, 111],\n",
       "         [112, 112, 112],\n",
       "         ...,\n",
       "         [105, 105, 105],\n",
       "         [105, 105, 105],\n",
       "         [105, 105, 105]],\n",
       "\n",
       "        [[111, 111, 111],\n",
       "         [111, 111, 111],\n",
       "         [112, 112, 112],\n",
       "         ...,\n",
       "         [106, 106, 106],\n",
       "         [106, 106, 106],\n",
       "         [106, 106, 106]],\n",
       "\n",
       "        [[111, 111, 111],\n",
       "         [111, 111, 111],\n",
       "         [112, 112, 112],\n",
       "         ...,\n",
       "         [106, 106, 106],\n",
       "         [106, 106, 106],\n",
       "         [106, 106, 106]]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([x_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6.926796e-04, 9.982860e-01]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([x_test[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
